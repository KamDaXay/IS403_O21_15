Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='BTC2019_2024_336_90', model='PatchTST', data='custom', root_path='./dataset/', data_path='BTC2019_2024.csv', features='MS', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=90, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=True, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : BTC2019_2024_336_90_PatchTST_custom_ftMS_sl336_ll48_pl90_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 845
test 456
Epoch: 1 cost time: 27.963372707366943
Epoch: 1, Steps: 6 | Train Loss: 0.9817244 Test Loss: 0.3044929
Validation loss decreased (inf --> 0.304493).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 27.399524450302124
Epoch: 2, Steps: 6 | Train Loss: 0.7618708 Test Loss: 0.1030078
Validation loss decreased (0.304493 --> 0.103008).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 27.67314648628235
Epoch: 3, Steps: 6 | Train Loss: 0.6259206 Test Loss: 0.1551334
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
Epoch: 4 cost time: 27.808187246322632
Epoch: 4, Steps: 6 | Train Loss: 0.6114161 Test Loss: 0.1239710
EarlyStopping counter: 2 out of 10
Updating learning rate to 9e-05
Epoch: 5 cost time: 27.57263159751892
Epoch: 5, Steps: 6 | Train Loss: 0.5037121 Test Loss: 0.1021215
Validation loss decreased (0.103008 --> 0.102122).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 27.589728832244873
Epoch: 6, Steps: 6 | Train Loss: 0.4701393 Test Loss: 0.1052817
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 27.54849672317505
Epoch: 7, Steps: 6 | Train Loss: 0.4417662 Test Loss: 0.1021019
Validation loss decreased (0.102122 --> 0.102102).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 27.639487504959106
Epoch: 8, Steps: 6 | Train Loss: 0.4208061 Test Loss: 0.0975795
Validation loss decreased (0.102102 --> 0.097579).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 27.8636212348938
Epoch: 9, Steps: 6 | Train Loss: 0.3838635 Test Loss: 0.0981840
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 27.439297199249268
Epoch: 10, Steps: 6 | Train Loss: 0.3778243 Test Loss: 0.1010658
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 27.4117431640625
Epoch: 11, Steps: 6 | Train Loss: 0.3697732 Test Loss: 0.1033453
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 27.620492696762085
Epoch: 12, Steps: 6 | Train Loss: 0.3462759 Test Loss: 0.1042757
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 27.46013307571411
Epoch: 13, Steps: 6 | Train Loss: 0.3268279 Test Loss: 0.1054331
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 27.614884853363037
Epoch: 14, Steps: 6 | Train Loss: 0.3187553 Test Loss: 0.1068667
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 27.612727642059326
Epoch: 15, Steps: 6 | Train Loss: 0.3140683 Test Loss: 0.1087847
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 28.012242555618286
Epoch: 16, Steps: 6 | Train Loss: 0.3098128 Test Loss: 0.1102984
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 27.587385416030884
Epoch: 17, Steps: 6 | Train Loss: 0.2980526 Test Loss: 0.1117034
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 27.464643478393555
Epoch: 18, Steps: 6 | Train Loss: 0.2940318 Test Loss: 0.1134015
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : BTC2019_2024_336_90_PatchTST_custom_ftMS_sl336_ll48_pl90_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 456
rmse: 0.3123771548271179, mse:0.0975794792175293, mape: 2.0747623443603516, mae:0.25994887948036194, rse:1.1454752683639526, mspe: 33.12093734741211, corr: [ 0.12694961  0.12409904  0.14385433  0.09999682  0.06680828  0.11410765
  0.13459583  0.12311208  0.12517074  0.07505947  0.11435127  0.1156193
  0.0725584   0.09576726  0.07737205  0.11689793  0.09470422  0.06564527
  0.11365148  0.08065285  0.12340023  0.13110267  0.11305834  0.10765052
  0.03482225  0.08380327  0.11491118  0.07996416  0.11525125  0.03311974
  0.10056773  0.06940908  0.07449297  0.01722012  0.11276889  0.08225194
  0.05972821  0.02206965  0.09185333  0.12101682  0.0389758   0.07665409
  0.05218721  0.11665642  0.03697123  0.09795064  0.10333951  0.09119818
  0.07152107  0.0577992   0.08670702  0.04345777 -0.03389534  0.10170761
  0.01924455  0.0037187   0.05475166 -0.04363713 -0.00065629  0.05206761
  0.00760766  0.08936325  0.04887033  0.01150525  0.09023871  0.01703406
  0.06670573  0.00639377  0.01917969  0.03576185  0.04471289  0.02951516
  0.09679791  0.0691973   0.05115397  0.02256762  0.07895464  0.07810381
  0.05079882  0.046576    0.05991583  0.04926489  0.1009593   0.06411673
  0.06295466  0.0720371   0.05098446  0.07652014  0.07158703  0.06344786]
>>>>>>>predicting : BTC2019_2024_336_90_PatchTST_custom_ftMS_sl336_ll48_pl90_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
pred 1
