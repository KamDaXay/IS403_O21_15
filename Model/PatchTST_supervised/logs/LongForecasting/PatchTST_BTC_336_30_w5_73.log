Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_30', model='PatchTST', data='custom', root_path='./dataset/', data_path='BTC.csv', features='MS', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=30, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=64, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 336_30_PatchTST_custom_ftMS_sl336_ll48_pl30_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 905
val 153
test 334
Epoch: 1 cost time: 33.112966775894165
Epoch: 1, Steps: 14 | Train Loss: 0.7972359 Vali Loss: 0.5408675 Test Loss: 0.2038328
Validation loss decreased (inf --> 0.540868).  Saving model ...
Updating learning rate to 4.148497583390264e-06
Epoch: 2 cost time: 33.319231033325195
Epoch: 2, Steps: 14 | Train Loss: 0.7240620 Vali Loss: 0.4497842 Test Loss: 0.1851253
Validation loss decreased (0.540868 --> 0.449784).  Saving model ...
Updating learning rate to 4.5930715197163254e-06
Epoch: 3 cost time: 32.41510367393494
Epoch: 3, Steps: 14 | Train Loss: 0.6560463 Vali Loss: 0.3400366 Test Loss: 0.1674557
Validation loss decreased (0.449784 --> 0.340037).  Saving model ...
Updating learning rate to 5.33097105251229e-06
Epoch: 4 cost time: 29.2736713886261
Epoch: 4, Steps: 14 | Train Loss: 0.5863574 Vali Loss: 0.2492439 Test Loss: 0.1503863
Validation loss decreased (0.340037 --> 0.249244).  Saving model ...
Updating learning rate to 6.3576305027195535e-06
Epoch: 5 cost time: 29.439208507537842
Epoch: 5, Steps: 14 | Train Loss: 0.5216911 Vali Loss: 0.1700610 Test Loss: 0.1335118
Validation loss decreased (0.249244 --> 0.170061).  Saving model ...
Updating learning rate to 7.666697518366462e-06
Epoch: 6 cost time: 30.11996865272522
Epoch: 6, Steps: 14 | Train Loss: 0.4572295 Vali Loss: 0.1188651 Test Loss: 0.1176751
Validation loss decreased (0.170061 --> 0.118865).  Saving model ...
Updating learning rate to 9.250072379106378e-06
Epoch: 7 cost time: 28.197503089904785
Epoch: 7, Steps: 14 | Train Loss: 0.3960008 Vali Loss: 0.0756713 Test Loss: 0.1031155
Validation loss decreased (0.118865 --> 0.075671).  Saving model ...
Updating learning rate to 1.109795811242175e-05
Epoch: 8 cost time: 27.820197820663452
Epoch: 8, Steps: 14 | Train Loss: 0.3536764 Vali Loss: 0.0556434 Test Loss: 0.0893852
Validation loss decreased (0.075671 --> 0.055643).  Saving model ...
Updating learning rate to 1.3198921111405145e-05
Epoch: 9 cost time: 28.58322548866272
Epoch: 9, Steps: 14 | Train Loss: 0.3061668 Vali Loss: 0.0485543 Test Loss: 0.0780526
Validation loss decreased (0.055643 --> 0.048554).  Saving model ...
Updating learning rate to 1.5539961879050668e-05
Epoch: 10 cost time: 30.592868328094482
Epoch: 10, Steps: 14 | Train Loss: 0.2680867 Vali Loss: 0.0492652 Test Loss: 0.0680952
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.810659546133274e-05
Epoch: 11 cost time: 30.53878164291382
Epoch: 11, Steps: 14 | Train Loss: 0.2397245 Vali Loss: 0.0497747 Test Loss: 0.0596839
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.088294107140069e-05
Epoch: 12 cost time: 28.400078058242798
Epoch: 12, Steps: 14 | Train Loss: 0.2140172 Vali Loss: 0.0543622 Test Loss: 0.0535582
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3851820350348184e-05
Epoch: 13 cost time: 28.38265347480774
Epoch: 13, Steps: 14 | Train Loss: 0.1919309 Vali Loss: 0.0565985 Test Loss: 0.0487889
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.699486365657935e-05
Epoch: 14 cost time: 28.3402578830719
Epoch: 14, Steps: 14 | Train Loss: 0.1738703 Vali Loss: 0.0630041 Test Loss: 0.0457556
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.0292623726116424e-05
Epoch: 15 cost time: 28.729414224624634
Epoch: 15, Steps: 14 | Train Loss: 0.1580060 Vali Loss: 0.0709201 Test Loss: 0.0441468
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.372469600058745e-05
Epoch: 16 cost time: 28.48963952064514
Epoch: 16, Steps: 14 | Train Loss: 0.1451076 Vali Loss: 0.0730029 Test Loss: 0.0433663
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.726984487837661e-05
Epoch: 17 cost time: 28.773017406463623
Epoch: 17, Steps: 14 | Train Loss: 0.1315539 Vali Loss: 0.0691746 Test Loss: 0.0417136
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.0906135107770936e-05
Epoch: 18 cost time: 28.344311714172363
Epoch: 18, Steps: 14 | Train Loss: 0.1261125 Vali Loss: 0.0728983 Test Loss: 0.0407174
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.461106750912171e-05
Epoch: 19 cost time: 28.6116681098938
Epoch: 19, Steps: 14 | Train Loss: 0.1137711 Vali Loss: 0.0713889 Test Loss: 0.0397800
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.836171818625286e-05
Epoch: 20 cost time: 28.40146827697754
Epoch: 20, Steps: 14 | Train Loss: 0.1109993 Vali Loss: 0.0747991 Test Loss: 0.0385246
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.2134880365760414e-05
Epoch: 21 cost time: 30.210099458694458
Epoch: 21, Steps: 14 | Train Loss: 0.1034798 Vali Loss: 0.0637361 Test Loss: 0.0367981
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.590720798658624e-05
Epoch: 22 cost time: 28.330528020858765
Epoch: 22, Steps: 14 | Train Loss: 0.0965637 Vali Loss: 0.0709891 Test Loss: 0.0362566
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.965536015141991e-05
Epoch: 23 cost time: 28.35825538635254
Epoch: 23, Steps: 14 | Train Loss: 0.0911503 Vali Loss: 0.0676076 Test Loss: 0.0356238
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.335614554615077e-05
Epoch: 24 cost time: 28.308462858200073
Epoch: 24, Steps: 14 | Train Loss: 0.0858554 Vali Loss: 0.0737903 Test Loss: 0.0353552
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.698666593378863e-05
Epoch: 25 cost time: 28.344806671142578
Epoch: 25, Steps: 14 | Train Loss: 0.0808133 Vali Loss: 0.0807859 Test Loss: 0.0358740
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.052445783499965e-05
Epoch: 26 cost time: 28.51355528831482
Epoch: 26, Steps: 14 | Train Loss: 0.0779675 Vali Loss: 0.0963166 Test Loss: 0.0375025
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.394763151862265e-05
Epoch: 27 cost time: 28.38293719291687
Epoch: 27, Steps: 14 | Train Loss: 0.0716876 Vali Loss: 0.1087660 Test Loss: 0.0381451
EarlyStopping counter: 18 out of 20
Updating learning rate to 7.723500644217668e-05
Epoch: 28 cost time: 28.52303171157837
Epoch: 28, Steps: 14 | Train Loss: 0.0671437 Vali Loss: 0.1694853 Test Loss: 0.0408048
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.036624230433485e-05
Epoch: 29 cost time: 28.403369903564453
Epoch: 29, Steps: 14 | Train Loss: 0.0632354 Vali Loss: 0.1716750 Test Loss: 0.0424941
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_30_PatchTST_custom_ftMS_sl336_ll48_pl30_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 334
mse:0.07805262506008148, mae:0.22338064014911652, rse:0.8466598987579346
