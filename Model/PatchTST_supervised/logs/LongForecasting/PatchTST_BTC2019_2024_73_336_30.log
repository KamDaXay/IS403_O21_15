Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='BTC2019_2024_336_30', model='PatchTST', data='custom', root_path='./dataset/', data_path='BTC2019_2024.csv', features='MS', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=30, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=True, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : BTC2019_2024_336_30_PatchTST_custom_ftMS_sl336_ll48_pl30_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 905
test 516
Epoch: 1 cost time: 44.7121376991272
Epoch: 1, Steps: 7 | Train Loss: 0.8134164 Test Loss: 0.3203915
Validation loss decreased (inf --> 0.320391).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 32.42264938354492
Epoch: 2, Steps: 7 | Train Loss: 0.5233395 Test Loss: 0.0876560
Validation loss decreased (0.320391 --> 0.087656).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 36.61867809295654
Epoch: 3, Steps: 7 | Train Loss: 0.3912172 Test Loss: 0.1014270
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
Epoch: 4 cost time: 30.801727533340454
Epoch: 4, Steps: 7 | Train Loss: 0.3250402 Test Loss: 0.0663279
Validation loss decreased (0.087656 --> 0.066328).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 27.51259732246399
Epoch: 5, Steps: 7 | Train Loss: 0.2426488 Test Loss: 0.0661715
Validation loss decreased (0.066328 --> 0.066172).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 27.943721055984497
Epoch: 6, Steps: 7 | Train Loss: 0.2156749 Test Loss: 0.0637551
Validation loss decreased (0.066172 --> 0.063755).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 29.21680188179016
Epoch: 7, Steps: 7 | Train Loss: 0.1854365 Test Loss: 0.0537872
Validation loss decreased (0.063755 --> 0.053787).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 28.184226512908936
Epoch: 8, Steps: 7 | Train Loss: 0.1649165 Test Loss: 0.0502030
Validation loss decreased (0.053787 --> 0.050203).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 27.645925045013428
Epoch: 9, Steps: 7 | Train Loss: 0.1500599 Test Loss: 0.0481289
Validation loss decreased (0.050203 --> 0.048129).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 30.617834091186523
Epoch: 10, Steps: 7 | Train Loss: 0.1355504 Test Loss: 0.0468353
Validation loss decreased (0.048129 --> 0.046835).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 27.873860120773315
Epoch: 11, Steps: 7 | Train Loss: 0.1283930 Test Loss: 0.0483084
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 27.95116662979126
Epoch: 12, Steps: 7 | Train Loss: 0.1263230 Test Loss: 0.0500116
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 28.827291011810303
Epoch: 13, Steps: 7 | Train Loss: 0.1202451 Test Loss: 0.0490899
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 27.145232915878296
Epoch: 14, Steps: 7 | Train Loss: 0.1154289 Test Loss: 0.0476731
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 27.77815008163452
Epoch: 15, Steps: 7 | Train Loss: 0.1115002 Test Loss: 0.0460678
Validation loss decreased (0.046835 --> 0.046068).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 27.31717824935913
Epoch: 16, Steps: 7 | Train Loss: 0.1086388 Test Loss: 0.0452873
Validation loss decreased (0.046068 --> 0.045287).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 27.442572832107544
Epoch: 17, Steps: 7 | Train Loss: 0.1095369 Test Loss: 0.0445924
Validation loss decreased (0.045287 --> 0.044592).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 35.28595209121704
Epoch: 18, Steps: 7 | Train Loss: 0.1061288 Test Loss: 0.0443567
Validation loss decreased (0.044592 --> 0.044357).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 30.187013149261475
Epoch: 19, Steps: 7 | Train Loss: 0.1043692 Test Loss: 0.0444348
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 31.62959623336792
Epoch: 20, Steps: 7 | Train Loss: 0.1027295 Test Loss: 0.0445151
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 33.31149339675903
Epoch: 21, Steps: 7 | Train Loss: 0.1013244 Test Loss: 0.0446439
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 36.562903881073
Epoch: 22, Steps: 7 | Train Loss: 0.1011994 Test Loss: 0.0446024
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 29.373783111572266
Epoch: 23, Steps: 7 | Train Loss: 0.0997830 Test Loss: 0.0444438
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 28.952815532684326
Epoch: 24, Steps: 7 | Train Loss: 0.0972965 Test Loss: 0.0443363
Validation loss decreased (0.044357 --> 0.044336).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 32.13330674171448
Epoch: 25, Steps: 7 | Train Loss: 0.0990557 Test Loss: 0.0441388
Validation loss decreased (0.044336 --> 0.044139).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 27.42224431037903
Epoch: 26, Steps: 7 | Train Loss: 0.0988789 Test Loss: 0.0438839
Validation loss decreased (0.044139 --> 0.043884).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 30.406270742416382
Epoch: 27, Steps: 7 | Train Loss: 0.0969046 Test Loss: 0.0436385
Validation loss decreased (0.043884 --> 0.043639).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 27.157654285430908
Epoch: 28, Steps: 7 | Train Loss: 0.0958257 Test Loss: 0.0434471
Validation loss decreased (0.043639 --> 0.043447).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 27.47265362739563
Epoch: 29, Steps: 7 | Train Loss: 0.0984361 Test Loss: 0.0434059
Validation loss decreased (0.043447 --> 0.043406).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 27.987414836883545
Epoch: 30, Steps: 7 | Train Loss: 0.0959957 Test Loss: 0.0434085
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 29.060266971588135
Epoch: 31, Steps: 7 | Train Loss: 0.0948045 Test Loss: 0.0433343
Validation loss decreased (0.043406 --> 0.043334).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 27.267303466796875
Epoch: 32, Steps: 7 | Train Loss: 0.0960506 Test Loss: 0.0433450
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 27.641921281814575
Epoch: 33, Steps: 7 | Train Loss: 0.0947264 Test Loss: 0.0433031
Validation loss decreased (0.043334 --> 0.043303).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 27.90192174911499
Epoch: 34, Steps: 7 | Train Loss: 0.0948869 Test Loss: 0.0433293
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 27.321815490722656
Epoch: 35, Steps: 7 | Train Loss: 0.0953338 Test Loss: 0.0433568
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 27.589505195617676
Epoch: 36, Steps: 7 | Train Loss: 0.0930065 Test Loss: 0.0432535
Validation loss decreased (0.043303 --> 0.043254).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 27.30295729637146
Epoch: 37, Steps: 7 | Train Loss: 0.0962452 Test Loss: 0.0431886
Validation loss decreased (0.043254 --> 0.043189).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 27.25138831138611
Epoch: 38, Steps: 7 | Train Loss: 0.0948610 Test Loss: 0.0431253
Validation loss decreased (0.043189 --> 0.043125).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 27.49927282333374
Epoch: 39, Steps: 7 | Train Loss: 0.0938925 Test Loss: 0.0431130
Validation loss decreased (0.043125 --> 0.043113).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 27.076329708099365
Epoch: 40, Steps: 7 | Train Loss: 0.0928359 Test Loss: 0.0431479
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 27.47823715209961
Epoch: 41, Steps: 7 | Train Loss: 0.0966103 Test Loss: 0.0431812
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 27.10233974456787
Epoch: 42, Steps: 7 | Train Loss: 0.0951658 Test Loss: 0.0431467
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 27.922431230545044
Epoch: 43, Steps: 7 | Train Loss: 0.0937633 Test Loss: 0.0432409
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 27.32104992866516
Epoch: 44, Steps: 7 | Train Loss: 0.0928210 Test Loss: 0.0431213
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 27.37431836128235
Epoch: 45, Steps: 7 | Train Loss: 0.0932618 Test Loss: 0.0430991
Validation loss decreased (0.043113 --> 0.043099).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 27.492958307266235
Epoch: 46, Steps: 7 | Train Loss: 0.0939476 Test Loss: 0.0430954
Validation loss decreased (0.043099 --> 0.043095).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 27.081591367721558
Epoch: 47, Steps: 7 | Train Loss: 0.0940421 Test Loss: 0.0431554
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 27.36948537826538
Epoch: 48, Steps: 7 | Train Loss: 0.0929727 Test Loss: 0.0431923
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 27.30113959312439
Epoch: 49, Steps: 7 | Train Loss: 0.0917416 Test Loss: 0.0431199
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 27.499864101409912
Epoch: 50, Steps: 7 | Train Loss: 0.0913801 Test Loss: 0.0431744
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 27.3059663772583
Epoch: 51, Steps: 7 | Train Loss: 0.0927542 Test Loss: 0.0431440
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 27.404442071914673
Epoch: 52, Steps: 7 | Train Loss: 0.0926740 Test Loss: 0.0431226
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 27.312151670455933
Epoch: 53, Steps: 7 | Train Loss: 0.0934869 Test Loss: 0.0431460
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 27.4180748462677
Epoch: 54, Steps: 7 | Train Loss: 0.0931418 Test Loss: 0.0431787
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 27.307725429534912
Epoch: 55, Steps: 7 | Train Loss: 0.0933343 Test Loss: 0.0432364
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 27.341549158096313
Epoch: 56, Steps: 7 | Train Loss: 0.0943868 Test Loss: 0.0432617
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : BTC2019_2024_336_30_PatchTST_custom_ftMS_sl336_ll48_pl30_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 516
rmse: 0.20759420096874237, mse:0.04309535026550293, mape: 0.8696358799934387, mae:0.1596621721982956, rse:0.488073468208313, mspe: 3.54028582572937, corr: [0.12204412 0.11395141 0.11727659 0.12142506 0.11591797 0.12308067
 0.11962094 0.12443868 0.11629255 0.11051915 0.11805212 0.11281562
 0.1152321  0.11660614 0.11654834 0.11408862 0.11101748 0.11424574
 0.11350993 0.10416157 0.12261067 0.11506735 0.12276725 0.11130743
 0.11879364 0.10863236 0.11631292 0.12075893 0.11953256 0.10791228]
>>>>>>>predicting : BTC2019_2024_336_30_PatchTST_custom_ftMS_sl336_ll48_pl30_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
pred 1
