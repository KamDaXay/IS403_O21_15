Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='BNB2019_2024_73_336_60', model='PatchTST', data='custom', root_path='./dataset/', data_path='BNB2019_2024.csv', features='MS', target='Close', freq='d', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=60, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=True, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : BNB2019_2024_73_336_60_PatchTST_custom_ftMS_sl336_ll48_pl60_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 875
test 486
Epoch: 1 cost time: 31.426103830337524
Epoch: 1, Steps: 6 | Train Loss: 0.8647301 Test Loss: 0.0994204
Validation loss decreased (inf --> 0.099420).  Saving model ...
Updating learning rate to 4.149208153775985e-06
Epoch: 2 cost time: 34.36369347572327
Epoch: 2, Steps: 6 | Train Loss: 0.8500275 Test Loss: 0.0953943
Validation loss decreased (0.099420 --> 0.095394).  Saving model ...
Updating learning rate to 4.595904987055895e-06
Epoch: 3 cost time: 33.110565423965454
Epoch: 3, Steps: 6 | Train Loss: 0.8111047 Test Loss: 0.0901615
Validation loss decreased (0.095394 --> 0.090162).  Saving model ...
Updating learning rate to 5.337313382765071e-06
Epoch: 4 cost time: 28.514116287231445
Epoch: 4, Steps: 6 | Train Loss: 0.7690246 Test Loss: 0.0837944
Validation loss decreased (0.090162 --> 0.083794).  Saving model ...
Updating learning rate to 6.368824000156984e-06
Epoch: 5 cost time: 28.578247547149658
Epoch: 5, Steps: 6 | Train Loss: 0.7374572 Test Loss: 0.0768037
Validation loss decreased (0.083794 --> 0.076804).  Saving model ...
Updating learning rate to 7.684023931114024e-06
Epoch: 6 cost time: 27.258885622024536
Epoch: 6, Steps: 6 | Train Loss: 0.6721273 Test Loss: 0.0699192
Validation loss decreased (0.076804 --> 0.069919).  Saving model ...
Updating learning rate to 9.274736569238537e-06
Epoch: 7 cost time: 27.7951078414917
Epoch: 7, Steps: 6 | Train Loss: 0.6324715 Test Loss: 0.0639703
Validation loss decreased (0.069919 --> 0.063970).  Saving model ...
Updating learning rate to 1.113107244386708e-05
Epoch: 8 cost time: 27.10213613510132
Epoch: 8, Steps: 6 | Train Loss: 0.5758604 Test Loss: 0.0600029
Validation loss decreased (0.063970 --> 0.060003).  Saving model ...
Updating learning rate to 1.3241490702972915e-05
Epoch: 9 cost time: 26.860937118530273
Epoch: 9, Steps: 6 | Train Loss: 0.5271258 Test Loss: 0.0586619
Validation loss decreased (0.060003 --> 0.058662).  Saving model ...
Updating learning rate to 1.5592870862717032e-05
Epoch: 10 cost time: 28.12203884124756
Epoch: 10, Steps: 6 | Train Loss: 0.5048538 Test Loss: 0.0600623
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.8170594377580232e-05
Epoch: 11 cost time: 26.841814041137695
Epoch: 11, Steps: 6 | Train Loss: 0.4844086 Test Loss: 0.0630339
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.095863552395426e-05
Epoch: 12 cost time: 26.883213996887207
Epoch: 12, Steps: 6 | Train Loss: 0.4477718 Test Loss: 0.0658036
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.3939661032168215e-05
Epoch: 13 cost time: 26.865471839904785
Epoch: 13, Steps: 6 | Train Loss: 0.4308627 Test Loss: 0.0660235
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.7095137847537134e-05
Epoch: 14 cost time: 27.106808185577393
Epoch: 14, Steps: 6 | Train Loss: 0.3998264 Test Loss: 0.0624348
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.0405448350481623e-05
Epoch: 15 cost time: 27.28872537612915
Epoch: 15, Steps: 6 | Train Loss: 0.3818171 Test Loss: 0.0561958
Validation loss decreased (0.058662 --> 0.056196).  Saving model ...
Updating learning rate to 3.385001231939466e-05
Epoch: 16 cost time: 26.798925161361694
Epoch: 16, Steps: 6 | Train Loss: 0.3711977 Test Loss: 0.0496433
Validation loss decreased (0.056196 --> 0.049643).  Saving model ...
Updating learning rate to 3.740741487801103e-05
Epoch: 17 cost time: 26.874579429626465
Epoch: 17, Steps: 6 | Train Loss: 0.3359063 Test Loss: 0.0459738
Validation loss decreased (0.049643 --> 0.045974).  Saving model ...
Updating learning rate to 4.105553963183036e-05
Epoch: 18 cost time: 26.84864068031311
Epoch: 18, Steps: 6 | Train Loss: 0.3303970 Test Loss: 0.0440546
Validation loss decreased (0.045974 --> 0.044055).  Saving model ...
Updating learning rate to 4.477170616588339e-05
Epoch: 19 cost time: 26.870956659317017
Epoch: 19, Steps: 6 | Train Loss: 0.3245287 Test Loss: 0.0441051
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.8532811049017215e-05
Epoch: 20 cost time: 26.871437788009644
Epoch: 20, Steps: 6 | Train Loss: 0.3080580 Test Loss: 0.0441238
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.2315471468074714e-05
Epoch: 21 cost time: 26.844346523284912
Epoch: 21, Steps: 6 | Train Loss: 0.2838805 Test Loss: 0.0448643
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.609617059899389e-05
Epoch: 22 cost time: 27.084589958190918
Epoch: 22, Steps: 6 | Train Loss: 0.2727743 Test Loss: 0.0446248
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.985140381105357e-05
Epoch: 23 cost time: 26.831915140151978
Epoch: 23, Steps: 6 | Train Loss: 0.2700980 Test Loss: 0.0437119
Validation loss decreased (0.044055 --> 0.043712).  Saving model ...
Updating learning rate to 6.355782479531338e-05
Epoch: 24 cost time: 27.06434178352356
Epoch: 24, Steps: 6 | Train Loss: 0.2491048 Test Loss: 0.0467644
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.71923907087659e-05
Epoch: 25 cost time: 26.8954176902771
Epoch: 25, Steps: 6 | Train Loss: 0.2516470 Test Loss: 0.0496034
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.073250543183931e-05
Epoch: 26 cost time: 26.692690134048462
Epoch: 26, Steps: 6 | Train Loss: 0.2403052 Test Loss: 0.0486552
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.415616004861761e-05
Epoch: 27 cost time: 26.895962715148926
Epoch: 27, Steps: 6 | Train Loss: 0.2269354 Test Loss: 0.0574594
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.744206967641173e-05
Epoch: 28 cost time: 27.07652521133423
Epoch: 28, Steps: 6 | Train Loss: 0.2291233 Test Loss: 0.0623309
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.05698057940118e-05
Epoch: 29 cost time: 27.078561544418335
Epoch: 29, Steps: 6 | Train Loss: 0.2142796 Test Loss: 0.0560498
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.351992324593426e-05
Epoch: 30 cost time: 26.851390600204468
Epoch: 30, Steps: 6 | Train Loss: 0.2280894 Test Loss: 0.0548962
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.62740811330781e-05
Epoch: 31 cost time: 27.06887173652649
Epoch: 31, Steps: 6 | Train Loss: 0.2149222 Test Loss: 0.0669553
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.881515683821217e-05
Epoch: 32 cost time: 27.96311044692993
Epoch: 32, Steps: 6 | Train Loss: 0.1983769 Test Loss: 0.0660447
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.112735247739609e-05
Epoch: 33 cost time: 28.4483482837677
Epoch: 33, Steps: 6 | Train Loss: 0.2025615 Test Loss: 0.0732895
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.31962931155261e-05
Epoch: 34 cost time: 27.040048599243164
Epoch: 34, Steps: 6 | Train Loss: 0.1956963 Test Loss: 0.0850254
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.50091161353985e-05
Epoch: 35 cost time: 27.042428493499756
Epoch: 35, Steps: 6 | Train Loss: 0.2029582 Test Loss: 0.0691296
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.655455120468343e-05
Epoch: 36 cost time: 26.893051147460938
Epoch: 36, Steps: 6 | Train Loss: 0.1766212 Test Loss: 0.0970369
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.782299034365299e-05
Epoch: 37 cost time: 26.589041471481323
Epoch: 37, Steps: 6 | Train Loss: 0.1799791 Test Loss: 0.1076967
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.880654765805293e-05
Epoch: 38 cost time: 28.25287961959839
Epoch: 38, Steps: 6 | Train Loss: 0.1663911 Test Loss: 0.0846847
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.949910836575763e-05
Epoch: 39 cost time: 27.384276866912842
Epoch: 39, Steps: 6 | Train Loss: 0.1640282 Test Loss: 0.1051681
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.989636681240981e-05
Epoch: 40 cost time: 27.623135805130005
Epoch: 40, Steps: 6 | Train Loss: 0.1513159 Test Loss: 0.1120114
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.999809616082395e-05
Epoch: 41 cost time: 27.530484437942505
Epoch: 41, Steps: 6 | Train Loss: 0.1480671 Test Loss: 0.1178198
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.990674029413367e-05
Epoch: 42 cost time: 27.618528127670288
Epoch: 42, Steps: 6 | Train Loss: 0.1449068 Test Loss: 0.1276005
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.967859406945825e-05
Epoch: 43 cost time: 27.69221329689026
Epoch: 43, Steps: 6 | Train Loss: 0.1461370 Test Loss: 0.1177414
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : BNB2019_2024_73_336_60_PatchTST_custom_ftMS_sl336_ll48_pl60_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 486
rmse: 0.20907381176948547, mse:0.04371185600757599, mape: 0.49792954325675964, mae:0.16710510849952698, rse:1.0658466815948486, mspe: 0.49335700273513794, corr: [0.11262847 0.12694034 0.12044883 0.12055615 0.10008755 0.11323054
 0.12335636 0.11013129 0.10896391 0.10071476 0.09999547 0.10388783
 0.11818063 0.10857042 0.08165987 0.08746522 0.09967638 0.09878417
 0.1064744  0.1020712  0.0978625  0.09566716 0.08123344 0.09912262
 0.08446336 0.0932553  0.09297856 0.07660116 0.08762224 0.09431022
 0.05921575 0.05765587 0.07654758 0.0978677  0.07361948 0.0678935
 0.06594115 0.06925452 0.07228688 0.06724659 0.0539873  0.06098269
 0.07197811 0.05099748 0.04196011 0.03448745 0.03889212 0.04314996
 0.03161082 0.02848829 0.04696323 0.01734066 0.04633202 0.00668418
 0.03729134 0.04534153 0.03375069 0.03416373 0.05128908 0.02076126]
>>>>>>>predicting : BNB2019_2024_73_336_60_PatchTST_custom_ftMS_sl336_ll48_pl60_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
pred 1
